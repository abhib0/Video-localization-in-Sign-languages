{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python script to Download a locale sign language video locally with its name.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Path to the WLASL.json file\n",
    "wlasl_file = \"WL-ASL/WLASL_v0.3.json\"\n",
    "\n",
    "# Path to the videos folder\n",
    "videos_folder = \"WL-ASL/videos\"\n",
    "\n",
    "# Load the WLASL.json file\n",
    "with open(wlasl_file, \"r\") as file:\n",
    "    wlasl_data = json.load(file)\n",
    "\n",
    "# Iterate over each entry in the WLASL data\n",
    "for entry in wlasl_data:\n",
    "    gloss = entry[\"gloss\"]\n",
    "    instances = entry[\"instances\"]\n",
    "\n",
    "    # Iterate over each instance for the current gloss\n",
    "    for instance in instances:\n",
    "        video_id = instance[\"video_id\"]\n",
    "        new_filename = f\"{gloss}.mp4\"\n",
    "\n",
    "        # Check if the video file exists in the videos folder\n",
    "        old_filepath = os.path.join(videos_folder, f\"{video_id}.mp4\")\n",
    "        if os.path.exists(old_filepath):\n",
    "            # Generate a new unique filename if the desired name already exists\n",
    "            count = 2\n",
    "            while os.path.exists(os.path.join(videos_folder, new_filename)):\n",
    "                new_filename = f\"{gloss}_{count}.mp4\"\n",
    "                count += 1\n",
    "\n",
    "            # Rename the video file\n",
    "            new_filepath = os.path.join(videos_folder, new_filename)\n",
    "            os.rename(old_filepath, new_filepath)\n",
    "            print(f\"Renamed {video_id}.mp4 to {new_filename}\")\n",
    "        else:\n",
    "            print(f\"Video file {video_id}.mp4 does not exist in the videos folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def download_mp4_files(checksums_file, output_folder):\n",
    "    with open(checksums_file, 'r') as file:\n",
    "        reader = csv.reader(file, delimiter='\\t')\n",
    "        next(reader)  # Skip the header row\n",
    "        for row in reader:\n",
    "            mp4_url = row[0]\n",
    "            word = row[3].split('.')[0].split('_')[1].lower()  # Extract the word from the file name\n",
    "            \n",
    "            # Create the output folder if it doesn't exist\n",
    "            os.makedirs(output_folder, exist_ok=True)\n",
    "            \n",
    "            # Download the MP4 file and save it with the word as the file name\n",
    "            response = requests.get(mp4_url)\n",
    "            file_path = os.path.join(output_folder, f\"{word}.mp4\")\n",
    "            \n",
    "            with open(file_path, 'wb') as mp4_file:\n",
    "                mp4_file.write(response.content)\n",
    "                \n",
    "            print(f\"Downloaded {word}.mp4\")\n",
    "\n",
    "# Usage example\n",
    "checksums_file = '/Users/abhib/Downloads/checksums.tsv'\n",
    "output_folder = '/Users/abhib/Desktop/untitled_folder/gem2'\n",
    "download_mp4_files(checksums_file, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def lemmatize_word(word):\n",
    "    doc = nlp(word)\n",
    "    lemmatized_word = doc[0].lemma_\n",
    "    return lemmatized_word\n",
    "\n",
    "# Set the paths to the CSV file, input folder, and output folder\n",
    "csv_path = '/Users/abhib/Desktop/untitled_folder/dataset.csv'\n",
    "input_folder = '/Users/abhib/Desktop/untitled_folder/CISLR_v1.5-a_videos'\n",
    "output_folder = '/Users/abhib/Desktop/untitled_folder/indian_sign'\n",
    "\n",
    "# Read the CSV file using pandas\n",
    "data = pd.read_csv(csv_path)\n",
    "\n",
    "# Iterate over each row in the CSV file\n",
    "for index, row in data.iterrows():\n",
    "    uid = row['uid']\n",
    "    gloss = str(row['gloss'])\n",
    "    gloss= lemmatize_word(gloss)\n",
    "\n",
    "    # Generate the input and output file paths\n",
    "    input_file = os.path.join(input_folder, f\"{uid}.mp4\")\n",
    "    output_file = os.path.join(output_folder, f\"{gloss}.mp4\")\n",
    "\n",
    "    # Copy the input file to the output folder\n",
    "    shutil.copyfile(input_file, output_file)\n",
    "\n",
    "    print(f\"Downloaded {gloss}.mp4\")\n",
    "\n",
    "print(\"Download completed!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trimming starting 1 sec and ending 1 sec of each word in dataset because they have still frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "input_folder = \"/Users/abhib/Desktop/untitled folder/untitled folder 4/video\"\n",
    "output_folder = \"/Users/abhib/Desktop/untitled folder/german_signs\"\n",
    "count=0\n",
    "# Iterate through all files in the input folder\n",
    "for file_name in os.listdir(input_folder):\n",
    "    \n",
    "        file_path = os.path.join(input_folder, file_name)\n",
    "        \n",
    "        # Get video length using MoviePy\n",
    "        video = VideoFileClip(file_path)\n",
    "        video_length = video.duration\n",
    "        \n",
    "        if video_length >= 5.0:\n",
    "            # Trim the video\n",
    "            trimmed_video = video.subclip(1.0, video_length - 1.0)\n",
    "            \n",
    "            # Construct output file path\n",
    "            output_file_path = os.path.join(output_folder, file_name)\n",
    "            \n",
    "            # Save the trimmed video with the same name, replacing the original video\n",
    "            trimmed_video.write_videofile(output_file_path, audio= False)\n",
    "            count=count+1\n",
    "            # Close the video file\n",
    "            trimmed_video.close()\n",
    "        \n",
    "        # Close the original video file\n",
    "        video.close()\n",
    "print(count)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading and trimming datasets from youtube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytube \n",
    "import os\n",
    "import ssl\n",
    "import json\n",
    "from moviepy.editor import *\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "api_key = 'AIzaSyD7ceRyObn4ICqHhu1Mjeii0WTDADu8fBk'\n",
    "youtube = build(\n",
    "    'youtube',\n",
    "    'v3',\n",
    "    developerKey = api_key,\n",
    ")\n",
    "\n",
    "import urllib3\n",
    "from urllib3.exceptions import IncompleteRead\n",
    "from http.client import IncompleteRead\n",
    "\n",
    "\n",
    "json_file_path = \"MS-ASL/MSASL_train.json\"\n",
    "folder1 = \"output_videos\"\n",
    "folder2 = \"trimmed_videos\"\n",
    "folder4 = \"folder4\"\n",
    "\n",
    "\n",
    "with open(json_file_path, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Dictionary to store downloaded source videos\n",
    "downloaded_videos = {}\n",
    "\n",
    "#for entry in data:\n",
    "for i, entry in enumerate(data[9791:], start=9792):\n",
    "    clean_text = entry[\"clean_text\"]\n",
    "    url = entry[\"url\"]\n",
    "    video_id = url.split('v=')[1]\n",
    "    if video_id == 'GOczM9jk2xY':\n",
    "        continue\n",
    "    if '&' in video_id:\n",
    "        video_id = video_id.split('&')[0]\n",
    "    if not url.startswith('http'):\n",
    "        url = 'https://' + url\n",
    "    start_time = entry[\"start_time\"]\n",
    "    end_time = entry[\"end_time\"]\n",
    "\n",
    "    # Check if the source video has already been downloaded\n",
    "    if url in downloaded_videos:\n",
    "        output_filename = downloaded_videos[url]\n",
    "    else:\n",
    "        # Download source video from URL and save it in folder1\n",
    "          # first check if the video url exists\n",
    "          request = youtube.videos().list(part = 'status', id = video_id )\n",
    "          response = request.execute()\n",
    "          if(len(response['items']) == 0 ):\n",
    "            print(\"video doesn't exists\")\n",
    "            continue\n",
    "          else:\n",
    "              try:\n",
    "                yt= pytube.YouTube(url)\n",
    "                ssl._create_default_https_context = ssl._create_unverified_context\n",
    "                output_filename = f\"{clean_text}.mp4\"\n",
    "                yt.streams.get_highest_resolution().download(folder1, filename=output_filename)\n",
    "                print(\"Downloaded\", url) \n",
    "              \n",
    "                # Add the downloaded video to the dictionary\n",
    "                downloaded_videos[url] = output_filename\n",
    "              \n",
    "              except OSError as e:\n",
    "                    print(f\"Error occurred while trimming video for '{clean_text}': {e}\")\n",
    "                    continue\n",
    "              except KeyError:\n",
    "                    print(\"Error occurred while accessing streamingData for video:\", url)\n",
    "                    continue  \n",
    "              except IncompleteRead:\n",
    "                    print(f\"IncompleteRead error occurred.)\")\n",
    "                    continue\n",
    "    # Trim video based on start_time and end_time and save it in folder2\n",
    "    trimmed_video_filename = f\"{clean_text}.mp4\"\n",
    "    trimmed_video_filepath = os.path.join(folder4, trimmed_video_filename)\n",
    "    source_video_filepath = os.path.join(folder1, output_filename)\n",
    "\n",
    "    # Check if the trimmed video already exists in folder4\n",
    "    if os.path.exists(trimmed_video_filepath):\n",
    "        # Append a count to the filename\n",
    "        count = 1\n",
    "        while True:\n",
    "            trimmed_video_filename = f\"{clean_text}_{count}.mp4\"\n",
    "            trimmed_video_filepath = os.path.join(folder4, trimmed_video_filename)\n",
    "            if not os.path.exists(trimmed_video_filepath):\n",
    "                break\n",
    "            count += 1\n",
    "\n",
    "              \n",
    "  # loading video gfg\n",
    "    try:         \n",
    "      clip = VideoFileClip(source_video_filepath)\n",
    "      # getting only first 5 seconds\n",
    "      trimmed_clip = clip.subclip(start_time, end_time)\n",
    "      trimmed_clip.write_videofile(trimmed_video_filepath)\n",
    "      print(f\"Downloaded and trimmed video for '{clean_text}'\")\n",
    "\n",
    "    except OSError as e:\n",
    "        print(f\"Error occurred while trimming video for '{clean_text}': {e}\")\n",
    "    except IncompleteRead as e:\n",
    "        print(f\"IncompleteRead error occurred for '{clean_text}'. Skipping video...\")\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred while processing video:\", e)\n",
    "\n",
    "\n",
    "print(\"All videos downloaded and trimmed successfully.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Videos of different dimensions (height and width) cannot be merged together.\n",
    "Resizing all the sign language word videos, so that all of them have equal dimensions and hence can be merged later.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "# Function to resize a video to the specified dimensions\n",
    "def resize_video(video_path, output_path, width, height):\n",
    "    video = VideoFileClip(video_path)\n",
    "    resized_video = video.resize((width, height))\n",
    "    resized_video.write_videofile(output_path, codec=\"libx264\", audio_codec=\"aac\")\n",
    "    video.close()\n",
    "    resized_video.close()\n",
    "# List of dataset folders\n",
    "#datasets = [\"folder4\", \"folder5\"]\n",
    "dataset =\"german_signs\"\n",
    "# Base path of the datasets\n",
    "base_path = \"/Users/abhib/Desktop/untitled_folder\"  # Replace with the actual base directory path\n",
    "# Iterate through each dataset folder\n",
    "#for dataset in datasets:\n",
    "dataset_path = os.path.join(base_path, dataset)\n",
    "    # Iterate through each video file in the dataset folder\n",
    "for filename in os.listdir(dataset_path):\n",
    "        if filename.endswith(\".mp4\"):\n",
    "            video_path = os.path.join(dataset_path, filename)\n",
    "            output_path = os.path.join(dataset_path, \"temp.mp4\")  # Temporary output file\n",
    "\n",
    "            # Get the dimensions of the video\n",
    "            video = VideoFileClip(video_path)\n",
    "            width, height = video.size\n",
    "            video.close()\n",
    "\n",
    "            # Check if the dimensions are already (480, 360)\n",
    "            if width == 640 and height == 480:\n",
    "                print(f\"{filename} dimensions are already good. Skipping...\")\n",
    "                continue\n",
    "            \n",
    "            # Resize the video to the specified dimensions\n",
    "            resize_video(video_path, output_path, 640, 480)\n",
    "            # Remove the original video file\n",
    "            os.remove(video_path)\n",
    "            # Rename the resized video file to the original file name\n",
    "            os.rename(output_path, video_path)\n",
    "# Cleanup temporary files\n",
    "#for dataset in datasets:\n",
    "dataset_path = os.path.join(base_path, dataset)\n",
    "temp_file_path = os.path.join(dataset_path, \"temp.mp4\")\n",
    "   # Remove any remaining temporary files\n",
    "if os.path.exists(temp_file_path):\n",
    "        os.remove(temp_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
